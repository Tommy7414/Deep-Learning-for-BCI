{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><font size=10>Feature extraction</font><br/>\n",
    "\n",
    "Feature extraction 是指通過領域知識從輸入信號中提取區分性特徵的過程。傳統特徵從 time-domain（例如，variance、mean value、kurtosis）、frequency-domain（例如，fast Fourier transform）和 time-frequency domains（例如，discrete wavelet transform）中提取。它們將豐富有關用戶意圖的可區分信息。<sup>1</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Manual-feature-extraction\" data-toc-modified-id=\"Manual-feature-extraction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Manual feature extraction</a></span></li><li><span><a href=\"#Automatical-feature-extraction\" data-toc-modified-id=\"Automatical-feature-extraction-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Automatical feature extraction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Autoencoder\" data-toc-modified-id=\"Autoencoder-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Autoencoder</a></span></li></ul></li><li><span><a href=\"#Reference\" data-toc-modified-id=\"Reference-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Reference</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual feature extraction \n",
    "\n",
    "手動 feature extraction 高度依賴於領域知識。例如，從 motor imagery EEG signal 提取獨特特徵需要神經科學知識。手動特徵提取也非常耗時且困難。當從大腦信號中手動提取特徵時，一些區分性特徵如 time-frequency features、wavelet entropy 和 band-specific power 是常見的選擇。\n",
    "\n",
    "深度學習的一個優勢是它可以在沒有領域知識的情況下自動學習 informative features 並發現 underlying patterns 。<font color=\"red\">在本教程中，我們只介紹如何從原始數據中學習 representative features，而不討論傳統的特徵提取方法。</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatical feature extraction\n",
    "\n",
    "Representative deep learning models 可以從輸入數據中自動學習純粹的 representative features\n",
    "這些 algorithms 僅具有特徵提取的功能，<font color=\"red\">但不能 classification</font>\n",
    "\n",
    "> 如下圖所示<sup>1</sup>：  \n",
    "代表性模型可以分為 Autoencoder (AE)、Restricted Boltzmann Machine (RBM) 和 Deep Belief Networks (DBN)。D-AE 表示 DeepAutoencoder，指的是具有多個隱藏層的 Autoencoder。同樣，D-RBM 表示 Deep-Restricted Boltzmann Machine，具有多個隱藏層。Deep Belief Network 可以由 AE 或 RBM 組成，因此，我們將 DBN 分為 DBN-AE 和 DBN-RBM。\n",
    "\n",
    "![avatar](https://raw.githubusercontent.com/xiangzhang1015/ML_BCI_tutorial/main/tutorial/dlm.PNG)\n",
    "\n",
    "__常用的深度學習表示算法有 AE、RBM、DBN 及其變體。__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder\n",
    "In this part, as an example of unsupervised feature extraction via deep learning, we will present the implementation of a simple framework that use AE as a feature extractor and feed the learned features to a standard KNN classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoEncoder：用於從原始數據中提取有用的特徵。這些特徵可以捕捉數據的潛在結構，並且可以用於後續的分類任務。\n",
    "\n",
    "KNN：用於評估 AutoEncoder 提取的特徵的分類效果。KNN 是一種簡單且直觀的分類算法，適合用來快速評估特徵的質量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_1 shape: (259520, 65)\n",
      "After segmentation, the shape of the data: (53628, 513)\n",
      "After normalization, the shape of training feature: (40221, 512) \n",
      "After normalization, the shape of test feature: (13407, 512)\n",
      "After reshape, the shape of training feature: (40221, 8, 64) \n",
      "After reshape, the shape of test feature: (13407, 8, 64)\n",
      "Epoch:  0 | STEP:  0 |Autoencoder train loss: 0.0084 |KNN accuracy: 0.6893\n",
      "Epoch:  50 | STEP:  0 |Autoencoder train loss: 0.0029 |KNN accuracy: 0.6611\n",
      "Epoch:  100 | STEP:  0 |Autoencoder train loss: 0.0023 |KNN accuracy: 0.6329\n",
      "Epoch:  150 | STEP:  0 |Autoencoder train loss: 0.0016 |KNN accuracy: 0.6472\n",
      "Epoch:  200 | STEP:  0 |Autoencoder train loss: 0.0015 |KNN accuracy: 0.6506\n",
      "Epoch:  250 | STEP:  0 |Autoencoder train loss: 0.0018 |KNN accuracy: 0.6482\n",
      "Epoch:  300 | STEP:  0 |Autoencoder train loss: 0.0202 |KNN accuracy: 0.4378\n",
      "Epoch:  350 | STEP:  0 |Autoencoder train loss: 0.0015 |KNN accuracy: 0.6506\n",
      "Epoch:  400 | STEP:  0 |Autoencoder train loss: 0.0010 |KNN accuracy: 0.6539\n",
      "BEST TEST ACC: 0.68926680092489\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import myimporter\n",
    "from BCI_functions import *  # BCI_functions.ipynb contains some functions we might use multiple times in this tutorial\n",
    "\n",
    "dataset_1 = np.load('1.npy')\n",
    "print('dataset_1 shape:', dataset_1.shape)\n",
    "\n",
    "# 移除 label \n",
    "removed_label = [2, 3, 4 ] # 至少 10 一定要移除（resting state）\n",
    "dataset_1 = dataset_1[~np.isin(dataset_1[:, -1], removed_label)]\n",
    "\n",
    "# data segmentation\n",
    "n_class = int(11-len(removed_label))  # 0~9 classes ('10:rest' is not considered)\n",
    "no_feature = 64  # the number of the features\n",
    "segment_length = 8  # selected time window; 16=160*0.1\n",
    "LR = 0.005  # learning rate\n",
    "EPOCH = 401\n",
    "\n",
    "data_seg = extract(dataset_1, n_classes=n_class, n_fea=no_feature, time_window=segment_length, moving=(segment_length/2))  # 50% overlapping\n",
    "print('After segmentation, the shape of the data:', data_seg.shape)\n",
    "\n",
    "# split training and test data\n",
    "no_longfeature = no_feature*segment_length\n",
    "data_seg_feature = data_seg[:, :no_longfeature]\n",
    "data_seg_label = data_seg[:, no_longfeature:no_longfeature+1]\n",
    "train_feature, test_feature, train_label, test_label = train_test_split(data_seg_feature, data_seg_label, shuffle=True)\n",
    "\n",
    "# normalization\n",
    "# before normalize reshape data back to raw data shape\n",
    "train_feature_2d = train_feature.reshape([-1, no_feature])\n",
    "test_feature_2d = test_feature.reshape([-1, no_feature])\n",
    "\n",
    "# min-max normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler3 = MinMaxScaler().fit(train_feature)\n",
    "train_fea_norm1 = scaler3.transform(train_feature)\n",
    "test_fea_norm1 = scaler3.transform(test_feature)\n",
    "print('After normalization, the shape of training feature:', train_fea_norm1.shape,\n",
    "      '\\nAfter normalization, the shape of test feature:', test_fea_norm1.shape)\n",
    "\n",
    "# 將 noramalize 後的數據重新塑形為 3D，以便輸入到 AutoEncoder  中\n",
    "train_fea_norm1 = train_fea_norm1.reshape([-1, segment_length, no_feature])\n",
    "test_fea_norm1 = test_fea_norm1.reshape([-1, segment_length, no_feature])\n",
    "print('After reshape, the shape of training feature:', train_fea_norm1.shape,\n",
    "      '\\nAfter reshape, the shape of test feature:', test_fea_norm1.shape)\n",
    "\n",
    "BATCH_size = train_fea_norm1.shape[0] # use test_data as batch size\n",
    "\n",
    "# feed data into dataloader\n",
    "train_fea_norm1 = torch.tensor(train_fea_norm1).type('torch.FloatTensor')\n",
    "train_label = torch.tensor(train_label.flatten())\n",
    "train_data = Data.TensorDataset(train_fea_norm1, train_label)\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_size, shuffle=False)\n",
    "\n",
    "test_fea_norm1 = torch.tensor(test_fea_norm1).type('torch.FloatTensor')\n",
    "test_label = torch.tensor(test_label.flatten())\n",
    "\n",
    "class AutoEncoder(nn.Module): # encoder 將輸入數據壓縮到 64*4 維，decoder 將其重建回原始維度\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(no_feature*segment_length, 64*4),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(64*4, no_feature*segment_length),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n",
    "\n",
    "autoencoder = AutoEncoder()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=LR)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "best_acc = []\n",
    "\n",
    "# classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "# training and testing\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (train_x, train_y) in enumerate(train_loader):\n",
    "\n",
    "        train_x = train_x.view(-1, no_feature*segment_length)\n",
    "        train_encoded, train_decoded = autoencoder(train_x)\n",
    "\n",
    "        loss = loss_func(train_decoded, train_x)  # mean square error\n",
    "        optimizer.zero_grad()  # clear gradients for this training step\n",
    "        loss.backward()  # backpropagation, compute gradients\n",
    "        optimizer.step()  # apply gradients\n",
    "\n",
    "        if epoch % 50 == 0 :\n",
    "            knn.fit(train_encoded.data.numpy(), train_y.data.numpy())\n",
    "            test_fea_norm1 = test_fea_norm1.view(-1, no_feature*segment_length)\n",
    "            test_encoded, test_decoded = autoencoder(test_fea_norm1)\n",
    "            knn_acc = knn.score(test_encoded.data.numpy(), test_label.data.numpy())\n",
    "\n",
    "            print('Epoch: ', epoch, '| STEP: ', step, '|Autoencoder train loss: %.4f' % loss.item(),'|KNN accuracy: %.4f' % knn_acc)\n",
    "            best_acc.append(knn_acc)\n",
    "\n",
    "print('BEST TEST ACC: {}'.format(max(best_acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_如上所見，這種組合的實驗表現不佳。原因可能追溯到數據集的特性。然而，對於不同的數據集，例如具有 fMRI 數據的數據集，autoencoder 可能會取得更好的表現。_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "<div id=\"refer-anchor-1\"></div>\n",
    "\n",
    "- [1]  [Zhang, X., Yao, L., Wang, X., Monaghan, J.J., Mcalpine, D. and Zhang, Y., 2020. A survey on deep learning-based non-invasive brain signals: recent advances and new frontiers. Journal of Neural Engineering.](https://iopscience.iop.org/article/10.1088/1741-2552/abc902/meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
