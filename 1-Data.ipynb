{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><font size=10>Data organization</font><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dataset-description\" data-toc-modified-id=\"Dataset-description-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Dataset description</a></span></li><li><span><a href=\"#Load-dataset\" data-toc-modified-id=\"Load-dataset-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Load dataset</a></span></li></ul></li><li><span><a href=\"#Resampling\" data-toc-modified-id=\"Resampling-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Resampling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Resampling-regarding-sampling-rate\" data-toc-modified-id=\"Resampling-regarding-sampling-rate-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Resampling regarding sampling rate</a></span></li><li><span><a href=\"#Resampling-regarding-data-size\" data-toc-modified-id=\"Resampling-regarding-data-size-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Resampling regarding data size</a></span></li></ul></li><li><span><a href=\"#Filtering\" data-toc-modified-id=\"Filtering-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Filtering</a></span></li><li><span><a href=\"#Reference\" data-toc-modified-id=\"Reference-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Reference</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we use the data from EEG Motor Movement/Imagery Dataset (EEG-MMIDB)[<sup>1</sup>](#refer-anchor-1). We offer the cleaned dataset that extract from the EEG-MMIDB that contains 109 subjects. In this tutorial, for simplicity, we take the first subject as a subset to show how the code works. The ready-to-use dataset can be find in the *dataset* folder.\n",
    "\n",
    "\n",
    "<!-- > Dataset_1: the data of the first subject in the EEG-MMIDB.  \n",
    "> Dataset_2: data of all 109 subjects of the EEG-MMIDB.\n",
    "\n",
    "* Note: in the following models of this BCI tutorial, we will use Dataset_1 to run examples for the computational advantage. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset description\n",
    "原始資料集描述可以在這裡找到：https://archive.physionet.org/pn4/eegmmidb/\n",
    "\n",
    "經過我們的清理和排序後，每個 .npy 檔案包含一個受試者的數據。每個 npy 檔案的數據形狀為 [N, 65]，前 64 columns 代表 64 個 EEG 通道的讀數，最後一 columns 表示 class/ intent 標籤。行表示信號收集中的時間點，每 rows 代表特定時間點的一個讀數。在本教程中，我們稱每 rows 為一個實例。EEG-MMIDB 的取樣率為 160 Hz，這意味著設備每秒可以生成 160 個實例/ rows /時間點。\n",
    "\n",
    "N 對不同的受試者有所不同，但 N 應該是 259,520 或 255,680。這是原始資料集中的固有差異。回想一下，取樣率是 160 Hz，因此，一些試驗持續 4.1 秒，而其他試驗持續 4.2 秒：4.1 秒（656=4.1 $\\times$ 160 實例）或 4.2 秒（672 = 4.2 $\\times$ 160 實例）。建議將信號分段為每秒。\n",
    "\n",
    "根據實驗設置，我們將所有 EEG 信號分為 11 種不同的 cognitive intentions 如下。其中，帶有 image 的意圖表示受試者僅想像動作而不實際移動：這四種 intentions（標記為 4、5、8 和 9）嚴格來說是 motion imagery EEG。其餘的 intention 則是用戶在進行特定動作時的心理狀態。\n",
    "\n",
    "> 標籤：  （看最後一行）    \n",
    "0: open eyes,  \n",
    "1: close eyes.  \n",
    "2: left hand,  \n",
    "3: right hand.  \n",
    "4: image left hand,  \n",
    "5: image right hand.  \n",
    "6: open fists,  \n",
    "7: open feet.  \n",
    "8: image fist,  \n",
    "9: image feet.  \n",
    "10: rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "Next, we show how to load the data in 2 commands!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of Dataset_1: (259520, 65)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-16, -29,   2, ..., -11,  15,   0],\n",
       "       [-56, -54, -27, ...,   1,  21,   0],\n",
       "       [-55, -55, -29, ...,  18,  35,   0],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,   0,   0,   9],\n",
       "       [  0,   0,   0, ...,   0,   0,   9],\n",
       "       [  0,   0,   0, ...,   0,   0,   9]], dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "dataset_1=np.load('1.npy') \n",
    "print('The shape of Dataset_1:', dataset_1.shape)\n",
    "dataset_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如上所見，受試者 1 的數據包含 259520 個 instances 和 64 個 channels，而最後一 columns 表示 class 標籤（ground truth）。\n",
    "\n",
    "我們首先介紹一些關於數據組織的術語：\n",
    "* Instance（time step 或 time point）。每個 instance 表示在單個時間點或取樣點收集的一組值。例如，對於取樣率為 160 Hz 的設備，在 1 秒內將有 160 個 instances。我們交替使用 instance 和 time point。\n",
    "\n",
    "* Segment（sample）。每個 segment 包含多個連續的 instances，可以表示大腦信號的特定事件/狀態。segment 的長度稱為 time window。我們交替使用 segment 和 sample。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling\n",
    "\n",
    "\n",
    "有時我們需要在進行任何分析之前調整 signal frequencies 或樣本比例。Resampling是一種從原始數據樣本中抽取重複樣本的方法<sup>2</sup>。有兩種類型的重取樣被廣泛使用：\n",
    "* Downsampling\n",
    "* Upsampling\n",
    "\n",
    "接下來，我們介紹在不同情況下重取樣的實現。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling regarding sampling rate\n",
    "\n",
    "在兩種情況下對輸入數據 Resampling \n",
    "\n",
    "* 第一種是處理multimodal signals。例如，我們想利用兩種不同的輸入信號：sampling rate 為 1000 Hz 的腦信號（EEG）和取樣率為 20 Hz 的心跳信號（ECG）。為了統一輸入數據並將它們整合在一起，我們需要將它們調整到一個固定的取樣率，比如說 200 Hz。實際操作很簡單，即從 EEG 的每五個連續 instances 中取一個 instance（downsampling；同時，將 ECG 中的每個 instance 重複 10 次（upsampling）\n",
    "\n",
    "* Resampling 也適用於輸入信號具有非常高的sampling rate而我們不需要的情況。以取樣率為 1000 Hz 的 EEG 數據為例：一個背景知識是 EEG 中最有用的信息在 70 Hz 以下，根據 Nyquist Sampling Theorem，我們只需要取樣率約為 140 Hz 的信號。為了減少計算成本，將原始高頻信號（1000 Hz）resample為低頻信號（例如 160 Hz）不是必須的，但可以接受。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling regarding data size\n",
    "\n",
    "用以保持數據集（包括training and testing set）之間的平衡。例如，我們有 1000 個 positive samples 但只有 200 個 negative samples，這在機器學習中稱為 *imbalance*。分類器可以通過盲目預測最頻繁的類別（即將所有預測都設為 positive prediction）來達到 80% 的準確率。為了解決這個問題，有三種典型的解決方案：\n",
    "1. Downsampling 最頻繁的類別直到達到更平衡的分佈（例如，隨機選擇多數類別的樣本並從訓練數據集中刪除它們）。\n",
    "2. Upsampling 最不頻繁的類別（例如，隨機複製少數類別的樣本）。\n",
    "3. 使用其他評估指標，如 ROC 曲線和 AUC（ROC 曲線下面積），這可以緩解數據不平衡問題。\n",
    "\n",
    "*在本教程中，我們不需要 Resampling，因為我們的數據具有適當的取樣頻率並且已經平衡。*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering\n",
    "\n",
    "Sometimes we need to filter the EEG signals into frequency bands of interests, in order to find the most informative and distinguishable patterns. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從任何典型的 EEG 硬體收集的 EEG 信號基於與特定行為狀態的 strong intraband correlation ，具有 nonoverlapping frequency bands（Delta、Theta、Alpha、Beta 和 Gamma）。每個 EEG 模式包含與特定大腦信息相關的信號。意識程度表示個體在面對外部刺激時的感知。這主要在生理學而非心理學中定義。<sup>3</sup>\n",
    "\n",
    "每個 frequency band 代表一種大腦狀態和對意識質性的評估：\n",
    "* Delta pattern (0.5--4 Hz) 對應於受試者意識較低時的深度睡眠。\n",
    "- Theta pattern (4--8 Hz) 對應於低意識範疇內的淺睡眠。\n",
    "* Alpha pattern (8--12 Hz) 主要出現在閉眼和深度放鬆狀態，對應於中等意識。\n",
    "* Beta pattern (12--30 Hz) 是受試者睜眼時的主要節律，與高意識相關。Beta 模式捕捉我們大多數的日常活動（如吃飯、走路和說話）。\n",
    "* Gamma pattern (30--100 Hz) 代表多個大腦區域共同進行特定運動和認知功能的互動。\n",
    "\n",
    "接下來，我們提供 filtering codes，以 Delta band 為例（本教程中不需要過濾，只是提供代碼以防讀者需要）。這裡使用的過濾器是 3-order band-pass butterworth filter。請調整 sampling frequency (fs)、lowcut 和 highcut 來定制自己的過濾器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "#     b, a = butter_bandpass(lowcut, highcut, fs, order=order) # butter_bandpass 是可以把 data 通過 lowcut 和 highcut 的訊號濾掉\n",
    "#     y = scipy.signal.lfilter(b, a, data)\n",
    "#     return y \n",
    "# def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "#     nyq = 0.5 * fs\n",
    "#     low = lowcut / nyq\n",
    "#     high = highcut / nyq\n",
    "#     b, a = butter(order, [low, high], btype='band')\n",
    "#     return b, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from BCI_functions.ipynb\n",
      "The shape of filtered feature: (259520, 64)\n",
      "The shape of dataset_1 after filtering: (259520, 65)\n"
     ]
    }
   ],
   "source": [
    "import myimporter  # 透過myimporter.py檔案，我們可以直接import ipynb檔案（要不然預設只能import py檔案）\n",
    "from BCI_functions import *  # BCI_functions.ipynb contains some functions we might use multiple times in this tutorial \n",
    "\n",
    "n_fea = 64  # 64 channels\n",
    "label = dataset_1[:, n_fea: n_fea+1]  # seperate label from feature\n",
    "feature = dataset_1[:, 0:n_fea] \n",
    "feature_f=[]  # feature after filtering\n",
    "\n",
    "# EEG Delta pattern decomposition\n",
    "for i in range(feature.shape[1]):\n",
    "    x = feature[:, i]\n",
    "    fs = 160.0\n",
    "    lowcut = 0.5\n",
    "    highcut = 4.0\n",
    "    y = butter_bandpass_filter(x, lowcut, highcut, fs, order=3)\n",
    "    feature_f.append(y) \n",
    "    \n",
    "feature_f=np.array(feature_f).T\n",
    "print('The shape of filtered feature:',feature_f.shape)\n",
    "\n",
    "data_f=np.hstack((feature_f,label))  # stack label to filtered feature \n",
    "print(\"The shape of dataset_1 after filtering:\",data_f.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "<div id=\"refer-anchor-1\"></div>\n",
    "\n",
    "- [1]  [Goldberger AL, Amaral LAN, Glass L, Hausdorff JM, Ivanov PCh, Mark RG, Mietus JE, Moody GB, Peng C-K, Stanley HE. PhysioBank, PhysioToolkit, and PhysioNet: Components of a New Research Resource for Complex Physiologic Signals. Circulation 101(23):e215-e220](http://circ.ahajournals.org/cgi/content/full/101/23/e215)\n",
    "\n",
    "<div id=\"refer-anchor-2\"></div>\n",
    "\n",
    "- [2]  [Resampling Imbalanced Data and Applying Machine Learning Techniques](https://medium.com/better-programming/resampling-imbalanced-data-and-applying-ml-techniques-91ebce40ff4d)\n",
    "\n",
    "<div id=\"refer-anchor-2\"></div>\n",
    "\n",
    "- [3]  [Zhang X, Yao L, Wang X, et al. A survey on deep learning-based non-invasive brain signals: recent advances and new frontiers[J]. Journal of Neural Engineering, 2020.](https://arxiv.org/abs/1905.04149)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
